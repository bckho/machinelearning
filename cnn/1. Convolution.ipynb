{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Convolution\r\n",
    "_Author: Maurice Snoeren_\r\n",
    "\r\n",
    "In this notebook we will investigate the convolution part of convolutional neural networks (CNNs). This is a special type of artificial neural network that is used within computer vision. In 2012 there was a breakthrough in the vision area. AlexNet competed in the ImageNet Large Scale Visual Recognition Challenge in 2012. This was a deep convolutional neural network, designed by Alex Krizhevsky. The network achieved a top-5 error of 15,3%. Object detection has been become feasable with this technology.\r\n",
    "\r\n",
    "Convolutional neural networks (CNNs) do something very mush different than normal artificial neural networks (ANNs). CNNs extract specific features from an image using the mathematical convolution. This convolution can be seen a filtering the image to extract lines, circles, etc. It contains a lot of layers and each convolution layer is able to extract more complex features. Where the first convolution layer matchers horizontal and vertical lines, the fifth convolution layer is able to extract full face features or trees for example. This made CNNs outperform existing methods. Normal ANNs are not able to detect a lot of different objects and large images are not easy to be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\r\n",
    "\r\n",
    "import cv2 \r\n",
    "import numpy as np\r\n",
    "\r\n",
    "def process_image(image):\r\n",
    "    image = cv2.imread(image) \r\n",
    "    image = cv2.cvtColor(src=image, code=cv2.COLOR_BGR2GRAY) \r\n",
    "    return image\r\n",
    "\r\n",
    "def convolve2D(image, kernel, padding=0, strides=1):\r\n",
    "    # Cross Correlation\r\n",
    "    kernel = np.flipud(np.fliplr(kernel))\r\n",
    "\r\n",
    "    # Gather Shapes of Kernel + Image + Padding\r\n",
    "    xKernShape = kernel.shape[0]\r\n",
    "    yKernShape = kernel.shape[1]\r\n",
    "    xImgShape = image.shape[0]\r\n",
    "    yImgShape = image.shape[1]\r\n",
    "\r\n",
    "    # Shape of Output Convolution\r\n",
    "    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\r\n",
    "    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\r\n",
    "    output = np.zeros((xOutput, yOutput))\r\n",
    "\r\n",
    "    # Apply Equal Padding to All Sides\r\n",
    "    if padding != 0:\r\n",
    "        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\r\n",
    "        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\r\n",
    "        print(imagePadded)\r\n",
    "    else:\r\n",
    "        imagePadded = image\r\n",
    "\r\n",
    "    # Iterate through image\r\n",
    "    for y in range(image.shape[1]):\r\n",
    "        # Exit Convolution\r\n",
    "        if y > image.shape[1] - yKernShape:\r\n",
    "            break\r\n",
    "        # Only Convolve if y has gone down by the specified Strides\r\n",
    "        if y % strides == 0:\r\n",
    "            for x in range(image.shape[0]):\r\n",
    "                # Go to next row once kernel is out of bounds\r\n",
    "                if x > image.shape[0] - xKernShape:\r\n",
    "                    break\r\n",
    "                try:\r\n",
    "                    # Only Convolve if x has moved by the specified Strides\r\n",
    "                    if x % strides == 0:\r\n",
    "                        output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\r\n",
    "                except:\r\n",
    "                    break\r\n",
    "\r\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale Image\r\n",
    "image = process_image('images/skyline.jpg')\r\n",
    "#image = process_image('images/test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0. 78. ... 44.  0.  0.]\n",
      " ...\n",
      " [ 0.  0. 40. ... 17.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection Kernel\r\n",
    "kernel = np.array(\r\n",
    "    [[-1, -1, -1],\r\n",
    "     [-1, 8, -1],\r\n",
    "     [-1, -1, -1]\r\n",
    "])\r\n",
    "\r\n",
    "output = convolve2D(image, kernel, padding=2)\r\n",
    "cv2.imwrite('images/image_edges.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0. 78. ... 44.  0.  0.]\n",
      " ...\n",
      " [ 0.  0. 40. ... 17.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection Kernel\r\n",
    "kernel = np.array(\r\n",
    "    [[-1, 0, 1],\r\n",
    "     [-1, 0, 1],\r\n",
    "     [-1, 0, 1]\r\n",
    "])\r\n",
    "\r\n",
    "output = convolve2D(image, kernel, padding=2)\r\n",
    "cv2.imwrite('images/image_right_edges.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0. 255. ... 255.   0.   0.]\n",
      " ...\n",
      " [  0.   0. 255. ... 255.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection Kernel\r\n",
    "kernel = np.array(\r\n",
    "    [[1, 0, -1],\r\n",
    "     [1, 0, -1],\r\n",
    "     [1, 0, -1]\r\n",
    "])\r\n",
    "\r\n",
    "output = convolve2D(image, kernel, padding=2)\r\n",
    "cv2.imwrite('images/image_left_edges.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0. 255. ... 255.   0.   0.]\n",
      " ...\n",
      " [  0.   0. 255. ... 255.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection Kernel\r\n",
    "kernel = np.array(\r\n",
    "    [[1, 1, 1],\r\n",
    "     [0, 0, 0],\r\n",
    "     [-1, -1, -1]\r\n",
    "])\r\n",
    "\r\n",
    "output = convolve2D(image, kernel, padding=2)\r\n",
    "cv2.imwrite('images/image_upper_edges.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0. 78. ... 44.  0.  0.]\n",
      " ...\n",
      " [ 0.  0. 40. ... 17.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Edge Detection Kernel\r\n",
    "kernel = np.array(\r\n",
    "    [[0, 0, 0, 0, 0],\r\n",
    "     [0, 1/9, 1/9, 1/9, 0],\r\n",
    "     [0, 1/9, 1/9, 1/9, 0],\r\n",
    "     [0, 1/9, 1/9, 1/9, 0],\r\n",
    "     [0, 0, 0, 0, 0],\r\n",
    "])\r\n",
    "\r\n",
    "output = convolve2D(image, kernel, padding=2)\r\n",
    "cv2.imwrite('images/image_blur.jpg', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\r\n",
    "\r\n",
    "- https://cs231n.github.io/convolutional-networks/\r\n",
    "- https://www.researchgate.net/profile/Paresh-Kamble/publication/333643310_Convolutional_Neural_Networks_-A_breakthrough_in_Computer_Vision/links/5cf901b9299bf1fb185bcee2/Convolutional-Neural-Networks-A-breakthrough-in-Computer-Vision.pdf\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python392jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}